{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Archon War began an indeterminate time in the past, and ended around 2,000 years ago.',\n",
       " 'During this period of time, many gods and archons roamed the land, locked in a bitter struggle for supremacy.',\n",
       " 'It appears that the battles associated with the Archon War are a multitude of local struggles that were grouped together by human history.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk as nt\n",
    "mytext = \"The Archon War began an indeterminate time in the past, and ended around 2,000 years ago. During this period of time, many gods and archons roamed the land, locked in a bitter struggle for supremacy. It appears that the battles associated with the Archon War are a multitude of local struggles that were grouped together by human history.\"\n",
    "\n",
    "my_sentences = nt.sent_tokenize(mytext)\n",
    "my_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Archon', 'War', 'began', 'an', 'indeterminate', 'time', 'in', 'the', 'past', ',', 'and', 'ended', 'around', '2,000', 'years', 'ago', '.']\n",
      "['During', 'this', 'period', 'of', 'time', ',', 'many', 'gods', 'and', 'archons', 'roamed', 'the', 'land', ',', 'locked', 'in', 'a', 'bitter', 'struggle', 'for', 'supremacy', '.']\n",
      "['It', 'appears', 'that', 'the', 'battles', 'associated', 'with', 'the', 'Archon', 'War', 'are', 'a', 'multitude', 'of', 'local', 'struggles', 'that', 'were', 'grouped', 'together', 'by', 'human', 'history', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in my_sentences:\n",
    "    print(nt.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Steps\n",
    "Langkah yang biasanya sering dilakukan dalam preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords\n",
    "Stopwords biasanya merupakan kata konjungsi atau tanda baca / angka yang tidak penting dalam pemrosesan bahasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess_corpus(texts):\n",
    "    # tentukan kriteria stopword berdasarkan bahasa\n",
    "    mystopwords = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def remove_stops_digits(tokens):\n",
    "        # hilangkan token yang berupa:\n",
    "        # stopwords, angka, dan punctuation (tanda baca)\n",
    "        return [token.lower() for (token) in tokens if (token not in mystopwords) and not (token.isdigit()) and (token not in punctuation)]\n",
    "    \n",
    "    return [remove_stops_digits(nt.word_tokenize(text)) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Archon War began an indeterminate time in the past, and ended around 2,000 years ago.\n",
      "['the', 'archon', 'war', 'began', 'indeterminate', 'time', 'past', 'ended', 'around', '2,000', 'years', 'ago']\n"
     ]
    }
   ],
   "source": [
    "removed_stopwrd = preprocess_corpus(my_sentences)\n",
    "print(my_sentences[0])\n",
    "print(removed_stopwrd[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming & Lemmatization\n",
    "Stemming merupakan proses mengubah kata menjadi kata dasar, sedangkan lemmatization merupakan proses mengubah kata menjadi kata yang sama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def stem_sentences(sentences):\n",
    "    # stem token-token\n",
    "    stemmer = PorterStemmer()\n",
    "    def stemming(sentence):\n",
    "        return [stemmer.stem(word) for word in sentence]\n",
    "    return [stemming(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears that the battles associated with the Archon War are a multitude of local struggles that were grouped together by human history.\n",
      "['it', 'appear', 'battl', 'associ', 'archon', 'war', 'multitud', 'local', 'struggl', 'group', 'togeth', 'human', 'histori']\n"
     ]
    }
   ],
   "source": [
    "stemmed_text = stem_sentences(removed_stopwrd)\n",
    "print(my_sentences[2])\n",
    "print(stemmed_text[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"better\", pos='a') # 'a' = adjective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The\n",
      "Lemma: the\n",
      "POS: DET\n",
      "\n",
      "Text: Archon\n",
      "Lemma: Archon\n",
      "POS: PROPN\n",
      "\n",
      "Text: War\n",
      "Lemma: War\n",
      "POS: PROPN\n",
      "\n",
      "Text: began\n",
      "Lemma: begin\n",
      "POS: VERB\n",
      "\n",
      "Text: an\n",
      "Lemma: an\n",
      "POS: DET\n",
      "\n",
      "Text: indeterminate\n",
      "Lemma: indeterminate\n",
      "POS: ADJ\n",
      "\n",
      "Text: time\n",
      "Lemma: time\n",
      "POS: NOUN\n",
      "\n",
      "Text: in\n",
      "Lemma: in\n",
      "POS: ADP\n",
      "\n",
      "Text: the\n",
      "Lemma: the\n",
      "POS: DET\n",
      "\n",
      "Text: past\n",
      "Lemma: past\n",
      "POS: NOUN\n",
      "\n",
      "Text: ,\n",
      "Lemma: ,\n",
      "POS: PUNCT\n",
      "\n",
      "Text: and\n",
      "Lemma: and\n",
      "POS: CCONJ\n",
      "\n",
      "Text: ended\n",
      "Lemma: end\n",
      "POS: VERB\n",
      "\n",
      "Text: around\n",
      "Lemma: around\n",
      "POS: ADV\n",
      "\n",
      "Text: 2,000\n",
      "Lemma: 2,000\n",
      "POS: NUM\n",
      "\n",
      "Text: years\n",
      "Lemma: year\n",
      "POS: NOUN\n",
      "\n",
      "Text: ago\n",
      "Lemma: ago\n",
      "POS: ADV\n",
      "\n",
      "Text: .\n",
      "Lemma: .\n",
      "POS: PUNCT\n",
      "\n",
      "Text: During\n",
      "Lemma: during\n",
      "POS: ADP\n",
      "\n",
      "Text: this\n",
      "Lemma: this\n",
      "POS: DET\n",
      "\n",
      "Text: period\n",
      "Lemma: period\n",
      "POS: NOUN\n",
      "\n",
      "Text: of\n",
      "Lemma: of\n",
      "POS: ADP\n",
      "\n",
      "Text: time\n",
      "Lemma: time\n",
      "POS: NOUN\n",
      "\n",
      "Text: ,\n",
      "Lemma: ,\n",
      "POS: PUNCT\n",
      "\n",
      "Text: many\n",
      "Lemma: many\n",
      "POS: ADJ\n",
      "\n",
      "Text: gods\n",
      "Lemma: god\n",
      "POS: NOUN\n",
      "\n",
      "Text: and\n",
      "Lemma: and\n",
      "POS: CCONJ\n",
      "\n",
      "Text: archons\n",
      "Lemma: archon\n",
      "POS: NOUN\n",
      "\n",
      "Text: roamed\n",
      "Lemma: roam\n",
      "POS: VERB\n",
      "\n",
      "Text: the\n",
      "Lemma: the\n",
      "POS: DET\n",
      "\n",
      "Text: land\n",
      "Lemma: land\n",
      "POS: NOUN\n",
      "\n",
      "Text: ,\n",
      "Lemma: ,\n",
      "POS: PUNCT\n",
      "\n",
      "Text: locked\n",
      "Lemma: lock\n",
      "POS: VERB\n",
      "\n",
      "Text: in\n",
      "Lemma: in\n",
      "POS: ADP\n",
      "\n",
      "Text: a\n",
      "Lemma: a\n",
      "POS: DET\n",
      "\n",
      "Text: bitter\n",
      "Lemma: bitter\n",
      "POS: ADJ\n",
      "\n",
      "Text: struggle\n",
      "Lemma: struggle\n",
      "POS: NOUN\n",
      "\n",
      "Text: for\n",
      "Lemma: for\n",
      "POS: ADP\n",
      "\n",
      "Text: supremacy\n",
      "Lemma: supremacy\n",
      "POS: NOUN\n",
      "\n",
      "Text: .\n",
      "Lemma: .\n",
      "POS: PUNCT\n",
      "\n",
      "Text: It\n",
      "Lemma: -PRON-\n",
      "POS: PRON\n",
      "\n",
      "Text: appears\n",
      "Lemma: appear\n",
      "POS: VERB\n",
      "\n",
      "Text: that\n",
      "Lemma: that\n",
      "POS: SCONJ\n",
      "\n",
      "Text: the\n",
      "Lemma: the\n",
      "POS: DET\n",
      "\n",
      "Text: battles\n",
      "Lemma: battle\n",
      "POS: NOUN\n",
      "\n",
      "Text: associated\n",
      "Lemma: associate\n",
      "POS: VERB\n",
      "\n",
      "Text: with\n",
      "Lemma: with\n",
      "POS: ADP\n",
      "\n",
      "Text: the\n",
      "Lemma: the\n",
      "POS: DET\n",
      "\n",
      "Text: Archon\n",
      "Lemma: Archon\n",
      "POS: PROPN\n",
      "\n",
      "Text: War\n",
      "Lemma: War\n",
      "POS: PROPN\n",
      "\n",
      "Text: are\n",
      "Lemma: be\n",
      "POS: AUX\n",
      "\n",
      "Text: a\n",
      "Lemma: a\n",
      "POS: DET\n",
      "\n",
      "Text: multitude\n",
      "Lemma: multitude\n",
      "POS: NOUN\n",
      "\n",
      "Text: of\n",
      "Lemma: of\n",
      "POS: ADP\n",
      "\n",
      "Text: local\n",
      "Lemma: local\n",
      "POS: ADJ\n",
      "\n",
      "Text: struggles\n",
      "Lemma: struggle\n",
      "POS: NOUN\n",
      "\n",
      "Text: that\n",
      "Lemma: that\n",
      "POS: DET\n",
      "\n",
      "Text: were\n",
      "Lemma: be\n",
      "POS: AUX\n",
      "\n",
      "Text: grouped\n",
      "Lemma: group\n",
      "POS: VERB\n",
      "\n",
      "Text: together\n",
      "Lemma: together\n",
      "POS: ADV\n",
      "\n",
      "Text: by\n",
      "Lemma: by\n",
      "POS: ADP\n",
      "\n",
      "Text: human\n",
      "Lemma: human\n",
      "POS: ADJ\n",
      "\n",
      "Text: history\n",
      "Lemma: history\n",
      "POS: NOUN\n",
      "\n",
      "Text: .\n",
      "Lemma: .\n",
      "POS: PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy, en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "doc = nlp(u'The Archon War began an indeterminate time in the past, and ended around 2,000 years ago. During this period of time, many gods and archons roamed the land, locked in a bitter struggle for supremacy. It appears that the battles associated with the Archon War are a multitude of local struggles that were grouped together by human history.')\n",
    "for token in doc:\n",
    "    # cara auto dapatin lemma, pos, dsb\n",
    "    print(\"Text: {0}\\nLemma: {1}\\nPOS: {2}\\n\".format(token.text, token.lemma_, token.pos_))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c3a4ba8f0a605bc784b58bf0abb4321a73521da8712a7a45623b3d418e73eb7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
